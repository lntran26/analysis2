"""
Snakefile for running N_t analysis on stdpopsim.

Simply running `snakemake` will run all analysis
defined by the arguments above.

Currently, for each rep,
This will run stairway plot, smc++, and msmc
on the data resulting from simulations
on all chromosomes included in chrm_list
for estimates of N_t (Ne through time).
"""

import pathlib
import sys
import os
import numpy as np
import stdpopsim
import stairway
import smc
import msmc
import gone
import plots
import masks

# TODO: smcpp
# TODO: gone
# TODO: check that constant works
# TODO: add census/coal lines to plots ... test plots in jupyter.nb w/ dataframes
# TODO: Add support for population_id list, right now it runs on all pops
# TODO: add support for running some but not all inference methods
# ###############################################################################
# GLOBALS
# ###############################################################################

configfile: "workflows/config/snakemake/tiny_config.yaml"

# The number of replicates of each analysis you would like to run
replicates = config["replicates"]

np.random.seed(config["seed"])
seed_array = np.random.random_integers(1, 2**31, replicates)
slim_scaling_factor=config["slim_scaling_factor"]

# Where you would like all output files from analysis to live
output_dir = os.path.abspath(config["output_dir"])
# The analysis species
species = stdpopsim.get_species(config["species"])

# The names of all chromosomes to simulate, separated by commas
# Use "all" to simulate all chromsomes for the genome
chrm_list = [chrom.id for chrom in species.genome.chromosomes]
if "chrY" in chrm_list:  # this is human specific
    chrm_list.remove("chrY")
if config["chrm_list"] != "all":
    chrm_list = [chr for chr in config["chrm_list"].split(",")]

# The specific demographic model you would like to run
demo_model_array = config["demo_models"]
demo_model_ids = [x["id"] for x in demo_model_array]
demo_sample_size_dict = {}
for x in demo_model_array:
    # demo_sample_size_dict[x["id"]] = x["num_samples_per_population"]
    model = species.get_demographic_model(x["id"])
    demo_sample_size_dict[x["id"]] = {
        f"{model.populations[i].name}": m
        for i, m in enumerate(x["num_samples_per_population"])
    }

# list of population names or specific id
# NOTE: currently not implemented
population_id = config["population_id"]

# Select DFE model from catalog
dfe_list = config["dfe_list"]
annotation_list = config["annotation_list"]

# The genetic map.if value None is given
# default_recombination_rates are used with a flat map
genetic_map_id = config["genetic_map"]
genetic_map_downloaded_flag = ".genetic_map_downloaded"

# TODO: mutation rate
# This grabs the default mut rate from the first chromosome,
# Ultimitely This needs to be replaced with the weighted average
# of all chromosomes: This should be done in stdpopsim.
mutation_rate = species.genome.mean_mutation_rate

# checks for mask file
try:
    mask_file = config["mask_file"]
except KeyError:
    mask_file = None

methods = config["methods"]
def pop_expand(output_dir, method, filename="temp.txt"):
    infiles = []
    for demog in demo_model_ids:
        for dfe, annot in zip(dfe_list, annotation_list):
            for seeds in seed_array:
                for chrms in chrm_list:
                    for pops in demo_sample_size_dict[demog].keys():
                        infiles.append(output_dir + f"/inference/{method}/{demog}/{dfe}/{annot}/{seeds}/{pops}/{method}_{filename}")
    return infiles
# ###############################################################################
# GENERAL RULES
# ###############################################################################


#module simulation_workflow:
#    snakefile:
#        "simulation.snake"
#    config:
#        config


#use rule * from simulation_workflow as simulation_*


localrules:
    download_genetic_map,
    download_msmc,
    sp_download,
    clone_smcpp,
    gone_clone,
    gone_copy,
    gone_params,
    all_plot,


rule all:
    input:
        expand(output_dir + "/plots/{demog}/estimated_Ne_t_final.csv",demog=demo_model_ids),
        expand(output_dir + "/plots/{demog}/estimated_Ne_t_final.pdf",demog=demo_model_ids),
        expand(output_dir + "/plots/{demog}/coal_estimated_Ne_t.csv", demog=demo_model_ids),
        expand(output_dir + "/plots/{demog}/{method}/{method}_estimated_Ne_t.csv",
            demog=demo_model_ids, method=methods),
        expand(output_dir + "/plots/{demog}/{method}/{method}_estimated_Ne_t.pdf",
            demog=demo_model_ids, method=methods),
        pop_expand(output_dir, "stairwayplot", "estimated_Ne.txt"),
        pop_expand(output_dir, "msmc", "estimated_Ne.txt"),
        pop_expand(output_dir, "gone", "estimated_Ne.txt"),
        #rules.simulation_all.output,


rule download_genetic_map:
    input:
    output:
        genetic_map_downloaded_flag,
    message:
        "Downloading default genetic map"
    run:
        # We need to have this here to avoid several threads trying to download the
        # the genetic map into the cache at the same time.
        if genetic_map_id is not None:
            genetic_map = species.get_genetic_map(genetic_map_id)
            if not genetic_map.is_cached():
                genetic_map.download()
            with open(output[0], "w") as f:
                print("File to indicate genetic map has been downloaded", file=f)


################################################################################
# UTILS HELPERS ETC
###############################################################################

def generation_time_helper(wildcards, species):
    if wildcards.demog == "Constant":
        generation_time = species.generation_time
    else:
        generation_time = species.get_demographic_model(wildcards.demog).generation_time
    return generation_time


rule write_bdd:
    output:
        output_dir + "/plots/{demog}/coal_estimated_Ne_t.csv",
    run:
        steps = None
        if wildcards.demog == "Constant":
            max_time = species.GenericConstantSize().default_population_size
            max_time *= 2  # 4?
            steps = np.linspace(1, max_time, max_time + 1)
        model = species.get_demographic_model(wildcards.demog)
        generation_time = generation_time_helper(wildcards, species)
        plots.gather_coal_rate(
            output,
            model,
            demo_sample_size_dict[wildcards.demog],
            generation_time,
            steps,
        )

# ###############################################################################
# STAIRWAYPLOT
# ###############################################################################
stairwayplot_code = config["stairwayplot_code"]
sp_mask = config["stairway_annot_mask"]

rule sp_download:
    output:
        directory("ext/stairwayplot"),
    message:
        "downloading stairwayplot"
    threads: 1
    shell:
        """
        cd ext/
        wget http://sesame.uoregon.edu/~adkern/stdpopsim/stairwayplot.tar.gz
        tar zxf stairwayplot.tar.gz
        rm -f stairwayplot.tar.gz
        cd ../
        """


rule run_stairwayplot:
    input:
        expand(
            [output_dir + "/simulated_data/{{demog}}/{dfes}/{annots}/{{seeds}}/sim_{{chrms}}.trees".format(
                dfes=DFE, annots=ANNOT) for (DFE, ANNOT) in zip(dfe_list, annotation_list)],
            demog=demo_model_ids,
            seeds=seed_array,
            chrms=chrm_list,
        ),
        rules.sp_download.output

    output:
        output_dir + "/inference/stairwayplot/{demog}/{dfes}/{annots}/{seeds}/{pops}/stairwayplot_estimated_Ne.txt"

    threads: 20
    resources:
        mem_mb=120000,
    run:
        gwildcards = glob_wildcards(output_dir + "/simulated_data/{demog}/{dfes}/{annots}/{seeds}/sim_{chrms}.trees")
        inputs = expand(
            output_dir
            + "/simulated_data/{demog}/{dfes}/{annots}/{seeds}/sim_{chrms}.trees",
            demog=wildcards.demog,
            dfes=wildcards.dfes,
            annots=wildcards.annots,
            seeds=wildcards.seeds,
            chrms=chrm_list,
        )

        runner = stairway.StairwayPlotRunner(
            workdir=output_dir
            + f"/inference/stairwayplot/{wildcards.demog}/{wildcards.dfes}/{wildcards.annots}/{wildcards.seeds}/{wildcards.pops}/",
            stairway_dir=pathlib.Path.cwd() / "ext/stairwayplot",
        )

        if wildcards.annots == "none" or sp_mask == "none":
            mask_intervals = masks.get_combined_masks(
                species.id,
                mask_file,
                gwildcards.chrms,
            )
        else:
            mask_intervals = masks.get_combined_masks(
                species.id,
                mask_file,
                gwildcards.chrms,
                chrom_annotation=wildcards.annots,
            )

        # TODO: change this back to 200
        runner.ts_to_stairway(
            inputs, wildcards.pops, mask_intervals=mask_intervals, num_bootstraps=10)
        runner.run_theta_estimation(max_workers=threads, show_progress=True)
        runner.run_summary(
            output,
            mutation_rate=mutation_rate,
            generation_time=generation_time_helper(wildcards, species),
        )


rule compound_stairwayplot:
    input: 
        pop_expand(output_dir, "stairwayplot", "estimated_Ne.txt")
    output:
        output_dir + "/plots/{demog}/stairwayplot/stairwayplot_estimated_Ne_t.csv",
    run:
        plots.gather_inference_results(output_dir, wildcards.demog, output[0], "stairwayplot",
                                       mask_file, sp_mask, demo_sample_size_dict[wildcards.demog],
                                       slim_scaling_factor)


rule plot_compound_stairway:
    input:
        rules.compound_stairwayplot.output,
    output:
        output_dir + "/plots/{demog}/stairwayplot/stairwayplot_estimated_Ne_t.pdf",
    run:
        plots.plot_compound_Ne_t(input[0], output[0], "stairwayplot")


# ###############################################################################
# MSMC2 https://github.com/stschiff/msmc2
# ###############################################################################
# sample size
num_sampled_genomes_msmc =  config["num_sampled_genomes_msmc"]
# The number of msmc Baumwelch iterations to run
num_msmc_iterations = config["num_msmc_iterations"]
num_sampled_genomes_per_replicate = config["num_sampled_genomes_per_replicate"]
msmc_exec = config["msmc_exec"]
msmc_mask = config["msmc_annot_mask"]

rule download_msmc:
    output:
        directory("ext/msmc2")
    message:
        "downloading msmc"
    threads: 1
    shell:
        """
        cd ext
	    git clone https://github.com/stschiff/msmc2.git
	    cat msmc2_makefile_stdpopsim_patch > msmc2/Makefile
	    cd msmc2
	    make
        cd ../../
        """

rule ts_to_multihep:
    input:
        expand(
        [output_dir + "/simulated_data/{{demog}}/{dfes}/{annots}/{{seeds}}/sim_{{chrms}}.trees".format(
            dfes=DFE, annots=ANNOT) for (DFE, ANNOT) in zip(dfe_list, annotation_list)],
        demog=demo_model_ids,
        seeds=seed_array,
        chrms=chrm_list,
        ),
    output:
        output_dir + "/inference/msmc/{demog}/{dfes}/{annots}/{seeds}/{pops}/{chrms}.trees.multihep.txt"

    run:
        print(input[0], num_sampled_genomes_msmc, mask_file)
        if wildcards.annots == "none" or msmc_mask == "none":
            mask_intervals = masks.get_combined_masks(
                                            species.id,
                                            mask_file,
                                            wildcards.chrms,
                                            )
        else:
            mask_intervals = masks.get_combined_masks(
                                            species.id,
                                            mask_file,
                                            wildcards.chrms,
                                            chrom_annotation=wildcards.annots,
                                            )
        msmc.write_msmc_file(input[0], output[0], wildcards.pops, mask_intervals)


rule run_msmc:
    input:
        #rules.ts_to_multihep.output,
        rules.download_msmc.output,
        inputs = expand(output_dir + "/inference/msmc/{{demog}}/{{dfes}}/{{annots}}/{{seeds}}/{{pops}}/{chrms}.trees.multihep.txt",
                    chrms=chrm_list,
                        )
    output:
        expand(output_dir + "/inference/msmc/{{demog}}/{{dfes}}/{{annots}}/{{seeds}}/{{pops}}/{samps}.trees.multihep.txt.final.txt",
            samps=num_sampled_genomes_msmc)
    threads: 8
    run:
        inputs = expand(output_dir + "/inference/msmc/{demog}/{dfes}/{annots}/{seeds}/{pops}/{chrms}.trees.multihep.txt",
                    demog=wildcards.demog,
                    dfes=wildcards.dfes,
                    annots=wildcards.annots,
                    seeds=wildcards.seeds,
                    pops=wildcards.pops,
                    chrms=chrm_list,
                        )
        total_samples = demo_sample_size_dict[wildcards.demog][wildcards.pops]
        input_file_string = " ".join(inputs)
        # TODO: get wildcards.samps to work so that num_sampled_genomes_msmc are run in parallel
        output_file_string = output_dir + f"/inference/msmc/{wildcards.demog}/{wildcards.dfes}/{wildcards.annots}/{wildcards.seeds}/{wildcards.pops}/"#{wildcards.samps}.trees.multihep.txt"
        msmc.run_msmc_estimate(input_file_string, output_file_string, msmc_exec, total_samples, num_sampled_genomes_msmc,
            iterations=num_msmc_iterations, ncores=threads) #wildcards.samps instead of num_sampled_genomes_msmc


rule convert_msmc:
    input:
        rules.run_msmc.output
    output:
        output_dir + "/inference/msmc/{demog}/{dfes}/{annots}/{seeds}/{pops}/msmc_estimated_Ne.txt"
    run:
        msmc.convert_msmc_output(input[0], output[0],
            mutation_rate=mutation_rate,
            generation_time=generation_time_helper(wildcards, species)
        )


rule compound_msmc:
    input: 
        pop_expand(output_dir, "msmc", "estimated_Ne.txt")
    output:
        output_dir + "/plots/{demog}/msmc/msmc_estimated_Ne_t.csv"
    run:
        plots.gather_inference_results(output_dir, wildcards.demog, output[0], "msmc",
                                       mask_file, msmc_mask, demo_sample_size_dict[wildcards.demog],
                                       slim_scaling_factor)       


rule plot_compound_msmc:
    input:
        rules.compound_msmc.output
    output:
        output_dir + "/plots/{demog}/msmc/msmc_estimated_Ne_t.pdf"
    run:
        plots.plot_compound_Ne_t(input[0], output[0], "msmc")


# ###############################################################################
# GONe
# ###############################################################################

gone_code = config["gone_code"]
gone_mask = config["gone_annot_mask"]

rule gone_clone:
    output:
        directory("ext/GONE")
    message:
        "cloning GONE repo"
    threads: 1
    shell:
        """
        cd ext/
        git clone https://github.com/esrud/GONE.git
        cd ..
        """


rule gone_params:
    input:
        rules.gone_clone.output,
    output:
        ".params_edited"
    message:
        "specifying GONE params"
    threads: 1
    run:
        prms = {"gone_phase":config["gone_phase"],
                "gone_max_snps":config["gone_max_snps"],
                "gone_num_gens":config["gone_num_gens"],
                "gone_num_bins":config["gone_num_bins"]}
        gone.params(gone_code, prms)


rule gone_copy:
    input:
        rules.gone_params.output,
        rules.gone_clone.output,

    output:
        output_dir + "/inference/gone/{demog}/{dfes}/{annots}/{seeds}/{chrms}/.scripts_copied"
    message:
        "copying GONE scripts into individual working directories"
    threads: 1
    run:
        print(output[0])
        outpath = "/".join(output[0].split("/")[:-1])
        gone.copy(gone_code, outpath, wildcards.seeds, threads)


rule gone_prep_inputs:
    input:
        output_dir + "/simulated_data/{demog}/{dfes}/{annots}/{seeds}/sim_{chrms}.trees",
    output:
        output_dir + "/inference/gone/{demog}/{dfes}/{annots}/{seeds}/{chrms}/gone.ped",
        output_dir + "/inference/gone/{demog}/{dfes}/{annots}/{seeds}/{chrms}/gone.map",
    threads: 1
    run:
        genetic_map = species.get_genetic_map(genetic_map_id)
        if not genetic_map.is_cached():
            genetic_map.download()
        gm_chr = genetic_map.get_chromosome_map(wildcards.chrms)
        # handle no annotation case
        if wildcards.annots == "none" or gone_mask == "none":
            mask_intervals = masks.get_combined_masks(
                                            species.id,
                                            mask_file,
                                            wildcards.chrms,
                                            )
        else:
            mask_intervals = masks.get_combined_masks(
                                            species.id,
                                            mask_file,
                                            wildcards.chrms,
                                            chrom_annotation=wildcards.annots,
                                            )
        gone.ts2plink(input[0], output[0], output[1], wildcards.pops, gm_chr, wildcards.chrms, mask_intervals=mask_intervals)


rule gone_run:
    input:
        rules.gone_copy.output,
        rules.gone_prep_inputs.output,
    output:
        output_dir + "/inference/gone/{demog}/{dfes}/{annots}/{seeds}/{chrms}/Output_Ne_gone",
    threads: 8
    resources: time=180
    shell:
        """
        cwd=$PWD
        cd {output_dir}/inference/gone/{wildcards.demog}/{wildcards.dfes}/{wildcards.annots}/{wildcards.seeds}/{wildcards.chrms}
        bash script_GONE.sh gone
        cd $cwd
        """

def ne_files_gone(wildcards):
    return expand(output_dir + "/inference/gone/{demog}/{dfes}/{annots}/{seeds}/{chrms}/Output_Ne_gone",
                seeds=seed_array,
                chrms=chrm_list,
                dfes=wildcards.dfes,
                demog=wildcards.demog,
                annots=wildcards.annots,
            )


rule compound_gone:
    input:
        ne_files_gone,
    output:
        output_dir + "/plots/{demog}/{chrms}/{dfes}/{annots}/dfe.inference.benchmark.pdf/gone_estimated_Ne.png"
    run: plots.plot_compound_gone(input, output[0])


rule compound_msmc:
    input: 
        pop_expand(output_dir, "msmc", "estimated_Ne.txt")
    output:
        output_dir + "/plots/{demog}/msmc/msmc_estimated_Ne_t.csv"
    run:
        plots.gather_inference_results(output_dir, wildcards.demog, output[0], "msmc",
                                       mask_file, msmc_mask, demo_sample_size_dict[wildcards.demog],
                                       slim_scaling_factor)       


rule plot_compound_msmc:
    input:
        rules.compound_msmc.output
    output:
        output_dir + "/plots/{demog}/msmc/msmc_estimated_Ne_t.pdf"
    run:
        plots.plot_compound_Ne_t(input[0], output[0], "msmc")

# ###############################################################################
#  Plotting results
# ###############################################################################

rule gather_inference:
    input:
        rules.compound_stairwayplot.output,
        rules.compound_msmc.output,
        #rules.compound_smcpp.output,
        #rules.compound_gone.output
    output:
        output_dir + "/plots/{demog}/estimated_Ne_t_final.csv",
    run:
        shell("echo 'method,population,nsamp,DFE,annotations,year,Ne,seed,chrm_mask,annot_mask,slim_scaling_factor' > {output[0]}.temp")
        for infile in input:
            shell("sed 1d {infile} >> {output[0]}.temp")
        shell("cut -d',' -f1-11 {output[0]}.temp > {output[0]}")
        shell("rm -f {output[0]}.temp")


rule all_plot:
    input:
        rules.gather_inference.output,
    output:
        output_dir + "/plots/{demog}/estimated_Ne_t_final.pdf",
    run:
        plots.plot_all_ne_estimates(input[0], output[0])